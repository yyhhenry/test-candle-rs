# test-candle-rs

使用Candle框架编写的最基础的MNIST示例，含CNN和全连接两种结构，包含训练和推理代码。

## 运行效率测试

截至2024-03的测试证明：

在双方都不使用cudnn的情况下，CUDA后端GPU推理速度上，`candle`与`PyTorch/tch-rs`相差无几。

但是`loss.backward()`函数在启用cudnn的情况下甚至比单纯启用cuda的情况下还要慢，似乎是其实现导致的。

此外，推理速度在cudnn加持下效果仍然不够明显，虽然的确有所加速，但是未达到`PyTorch`的水平。

更多有关运行效率的信息，见[torch-mnist-bench](https://github.com/yyhhenry/torch-mnist-bench)

截至2024-07的测试证明：

Cudnn略微降低了训练速度，但是收敛速度有所提升，目前未知原因。

在大量小矩阵相乘的例子上（一个典型的GPU不如CPU的例子），`candle`的CPU运行比`tch-rs`更快，但是CUDA运行比`tch-rs`略慢。使用f32还是f64对CUDA计算有一定的影响，是否开启cudnn对这个简单例子毫无影响。

以下是两次运行结果：

```txt
# CPU
==== Directly Matmul ====
n: 10000000, 1e7 elements
Direct result: Tensor[dims 10000000, 3, 3; f32]
Samples: Ok([[0.49641514, -0.067511626, 0.13594563], [-0.70245403, 0.51553804, -0.62102944], [-1.3690482, -2.950206, 2.4649305]]) Ok([[-2.4999757, -0.20409973, 1.0095311], [-0.84369165, 2.377748, -0.98420316], [0.6863668, -0.73658305, 0.9311778]])
Elapsed: 1.8894209s
==== Directly Matmul ====
==== Loop Matmul ====
n: 100000, 1e5 elements
Results: Tensor[dims 100000, 3, 3; f32]
Samples: Ok([[0.24911392, -0.48722735, -1.0141929], [0.02874751, 1.9635211, 0.5881494], [0.16735125, 0.2819953, -0.46391773]]) Ok([[0.64836234, -0.97360814, 0.035052266], [-0.740371, -1.664242, 0.58205223], [-0.05148498, -1.2575049, -2.7739928]])
Elapsed: 168.5871ms
==== Loop Matmul ====

# GPU
==== Directly Matmul ====
n: 10000000, 1e7 elements
Direct result: Tensor[dims 10000000, 3, 3; f32, cuda:0]
Samples: Ok([[3.7823868, 1.2092516, 2.1999369], [-0.27577233, -0.33836123, -0.44703394], [0.20691925, 0.18453076, 0.69118947]]) Ok([[2.014108, 0.3556413, 0.3760209], [-0.441907, 1.1436259, -0.62014973], [-0.2610164, 0.5109947, -0.39668667]])
Elapsed: 245.1974ms
==== Directly Matmul ====
==== Loop Matmul ====
n: 100000, 1e5 elements
Results: Tensor[dims 100000, 3, 3; f32, cuda:0]
Samples: Ok([[-0.015581965, -0.27481112, -0.8990948], [-0.66714025, -1.5256379, -1.2191229], [0.04039287, -0.05080761, 0.03581176]]) Ok([[-1.0934627, -1.5790086, 0.15148754], [0.298453, 0.42905277, -0.4997509], [0.9878696, 0.38054, -1.3213916]])
Elapsed: 2.0232764s
==== Loop Matmul ====
```
